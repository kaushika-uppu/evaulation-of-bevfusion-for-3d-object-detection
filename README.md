# Evaluating Performance of LiDAR and Camera Fused 3D Object Detection Using BEVFusion

*Kaushika Uppu, Sravani Neelapala, Loi Nguyen, Hau Nguyen*


***Abstract*** â€” Autonomous driving significantly relies on the ability to detect and localize 3D objects within a complex environment. Two inputs typically used for this problem are LiDAR (Light Detection and Ranging) and cameras. With both technologies having pros and cons, using a fusion of LiDAR and cameras could lead to a more comprehensive 3D perception system with higher accuracy and robustness. This project aimed to integrate BEVFusion, a state-of-the-art multi-sensor fusion framework, into a ROS-2 environment to evaluate 3D object detection on the NuScenes dataset.

## Setting Up Project

- For detailed instructions and commands on how this project was setup for the HPC A40 GPU, please refer to the `a40gpu_setup.md` file.
- For detailed instructions and commands on how this project was setup for the P100 GPU, please refer to the `p100_setup.md` file.
- For detailed instructions and commands on how this project was setup for the Jetson Orin Nano, please refer to the `BEVFusion_SETUP.md` file in the `ros2-bevfusion-jetson-main` folder.
- For detailed instructions and commands on how this project was setup for the T4 GPU, please refer to the `README.md` file in the `Google colab` folder.
